## Тестовое задание на devops-инженера в медицинский проект по пунктам:

1. В файле main.go (Go SDK 1.21.6) содержится код простейшего http-сервера, который обслуживает два эндпоинта согласно заданию. Слушает 3000-й порт.

2. Dockerfile реализован в виде multistage сборки, с помощью golang имаджа собирается бинарник ./test, потом он копируется в имадж с минимальным размером и возможностями в /app/test. В /app также копируются дополнительные необходимые файлы из проекта.

3. Helm chart находится по пути .infra/k8s/test, содержит код, который соответствует заданию. ConfigMap монтируется в под по пути /app/message.html. Созданы startup и liveness probes и три реплики. Т.к. доступ извне для кластеров на локальных компах для разных систем реализован по-разному (я использую minikube с docker драйвером), поэтому я присвоил сервису test тип ClusterIP, чтобы использовать стандартный для всех систем port-forward:
```sh
kubectl -n test port-forward svc/test 3000:3000
```
и после из броузера:
```sh
http://localhost:3000
```

4. Bash-скрипт script.sh содержит код, который полностью автоматизирует процессы сборки имаджа, выгрузки имаджа в Docker Hub и развёртывания helm релиза с этим имаджем в kubernetes в namespace test. Я использовал Docker Hub, если использовать другой registry, то надо поменять переменную REGISTRY_URL в функции docker_login(). Утилита yq меняет значения appVersion в Chart.yaml и .image.tag в values.yaml на значения тэга имаджа. Я специально разбил каждый шаг на функции для более удобного анализа кода, поэтому код выглядит не совсем идеально. Запуск скрипта происходит следующим образом:

```sh
./script.sh registry_url/namespace/repository:tag
```
Пример:
```sh
gcr.io/k8s-minikube/kicbase:v0.0.42
```
5. Проект находится на [GitHub](https://github.com/semirski/web-test).

6. Что касается мониторинга и логирования. Так получается, что в последние лет 5 я приходил на проекты с уже работающими системами, и в мои обязанности никогда не входила настройка и ведение этих систем. И со сложными системами я не сталкивался. Всегда это был просто отдельный namespace, в котором и располагались все компоненты этих систем. Только на одном проекте я подошёл к ним близко. Надо было разработать с нуля чарт для ELK стэка, и значительно переработать prometheus чарт (нужны были тимплейты конфигов для различных кластеров). Дома, при необходимости, я использую kube prometheus stack:
```sh
kubectl create namespace monitoring
kubens monitoring
helm install prometheus prometheus-community/kube-prometheus-stack
watch kubectl get pod -A -o wide
```
Я приложил к проекту две картинки из инета, которые, по моему мнению, наиболее точно коцептуально отображают эти системы в минимальном их виде.

Наверное, пока всё. Будут вопросы - мой телеграм `@semirski`.